{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306a1f55-3f9d-4996-be95-e11e5a74a86b",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Set working directory to top level of repo to ensure links work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9907dc-c0d2-4b2e-8cbb-bb3a2bc15f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Robbi/dea-intertidal\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586a481-013f-4884-8e53-f3ddb9c438d7",
   "metadata": {},
   "source": [
    "Install additional packages directly from the requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67433e6-0408-40d1-be61-db49c52f88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.in --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244cc06-b5e7-4120-8514-adf35082cb2c",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67df5808-fa99-4c4c-860e-b02001896270",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from ipyleaflet import basemaps, basemap_to_tiles\n",
    "\n",
    "import datacube\n",
    "import odc.geo.xr\n",
    "from odc.geo.geom import Geometry\n",
    "from odc.geo.geobox import GeoBox\n",
    "from odc.ui import select_on_a_map\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "from dea_tools.coastal import pixel_tides\n",
    "\n",
    "# from intertidal.tide_modelling import pixel_tides_ensemble\n",
    "from intertidal.io import load_data, load_topobathy_mask, prepare_for_export\n",
    "from intertidal.elevation import (\n",
    "    ds_to_flat,\n",
    "    pixel_rolling_median,\n",
    "    pixel_dem,\n",
    "    pixel_dem_debug,\n",
    "    pixel_uncertainty,\n",
    "    flat_to_ds,\n",
    "    clean_edge_pixels,\n",
    "    elevation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935057ff-f0b2-4d29-b137-2faf8655463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def pc_load(\n",
    "    product,\n",
    "    time=None,\n",
    "    x=None,\n",
    "    y=None,\n",
    "    geom=None,\n",
    "    stac_query=None,\n",
    "    url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    **load_params,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads data from Microsoft Planetary Computer into an\n",
    "    `xarray.Dataset` using `odc-stac`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    product : str\n",
    "        The name of the product to load.\n",
    "    time : tuple, optional\n",
    "        The time range to load data for as a tuple of strings (e.g.\n",
    "        `(\"2020\", \"2021\")`. If not provided, data will be loaded for\n",
    "        all available timesteps.\n",
    "    x, y : tuple, optional\n",
    "        Tuples defining the x and y bounding box to load, in WGS 84.\n",
    "    geom : datacube Geometry, optional\n",
    "        A datacube geometry object representing the spatial extents to\n",
    "        load data for. If provided, `x` and `y` will be ignored.\n",
    "    stac_query : dict, optional\n",
    "        A query dictionary to further filter the data using STAC metadata.\n",
    "        If not provided, no additional filtering will be applied.\n",
    "    url : str, optional\n",
    "        The URL of the Planetary Computer STAC API.\n",
    "        Defaults to \"https://planetarycomputer.microsoft.com/api/stac/v1\".\n",
    "    **load_params : dict\n",
    "        Additional parameters to be passed to `odc.stac.load()`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray.Dataset\n",
    "        The loaded dataset as an `xarray.Dataset`.\n",
    "    items : pystac.item_collection.ItemCollection\n",
    "        STAC items returned by `pystac_client`.\n",
    "    \"\"\"\n",
    "\n",
    "    import odc.stac\n",
    "    import planetary_computer\n",
    "    import pystac_client\n",
    "    from odc.geo.geom import BoundingBox\n",
    "\n",
    "    # Connect to client\n",
    "    catalog = pystac_client.Client.open(\n",
    "        url,\n",
    "        modifier=planetary_computer.sign_inplace\n",
    "        if \"planetarycomputer\" in url\n",
    "        else None,\n",
    "    )\n",
    "    \n",
    "    # Set up time for query\n",
    "    time_range = \"/\".join(time) if time is not None else None\n",
    "   \n",
    "    # Set up bounding box for query\n",
    "    if geom is not None:\n",
    "        bbox = geom.boundingbox\n",
    "    else:\n",
    "        bbox = BoundingBox.from_xy(x, y)\n",
    "\n",
    "    # Ensure longitude is between -180 to 180:\n",
    "    if (bbox.left >= 180) or (bbox.right >= 180):\n",
    "        bbox = BoundingBox(\n",
    "            left=bbox.left - 360,\n",
    "            bottom=bbox.bottom,\n",
    "            right=bbox.right - 360,\n",
    "            top=bbox.top,\n",
    "        )\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=product,\n",
    "        bbox=bbox,\n",
    "        datetime=time_range,\n",
    "        query=stac_query if stac_query is not None else None,\n",
    "    )\n",
    "\n",
    "    # Check how many items were returned\n",
    "    items = search.item_collection()\n",
    "    print(f\"Found {len(items)} STAC items for {product}\")\n",
    "\n",
    "    # Load with ODC STAC\n",
    "    ds = odc.stac.load(\n",
    "        items=items,\n",
    "        bbox=bbox,\n",
    "        **load_params,\n",
    "    )\n",
    "\n",
    "    return ds, items\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def load_ls_s2(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    geom=None,\n",
    "    start_date=\"2020\",\n",
    "    end_date=\"2021\",\n",
    "    resolution=30,\n",
    "    cloud_cover=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load NDWI from Landsat and Sentinel-2 hosted on Microsoft Planetary\n",
    "    Computer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : tuple, optional\n",
    "        Tuples defining the x and y bounding box to load, in WGS 84.\n",
    "    geom : datacube Geometry, optional\n",
    "        A datacube geometry object representing the spatial extents to\n",
    "        load data for. If provided, `x` and `y` will be ignored.\n",
    "    start_date, end_date : strings, optional\n",
    "        The start and end of the time period to load, expressed as\n",
    "        strings (e.g. \"2020\", \"2021\"; \"2020-01\", \"2021-02\")\n",
    "    resolution : int, optional\n",
    "        Spatial resolution to load data in. Defaults to 30 metres.\n",
    "    cloud cover : int, optional\n",
    "        The maximum threshold of cloud cover to load. Defaults to 10%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    satellite_ds : xarray.Dataset\n",
    "        The loaded dataset as an `xarray.Dataset`, containing a single\n",
    "        \"ndwi\" `xarray.DataArray`.\n",
    "    \"\"\"\n",
    "\n",
    "    query_params = dict(\n",
    "        time=(start_date, end_date),\n",
    "        geom=geom if geom is not None else None,\n",
    "        x=x if geom is None else None,\n",
    "        y=y if geom is None else None,\n",
    "    )\n",
    "\n",
    "    load_params = dict(\n",
    "        crs=\"utm\",\n",
    "        resolution=resolution,\n",
    "        chunks={\"x\": 2048, \"y\": 2048},\n",
    "        groupby=\"solar_day\",\n",
    "        resampling={\"qa_pixel\": \"nearest\", \"SCL\": \"nearest\", \"*\": \"cubic\"},\n",
    "        fail_on_error=True,\n",
    "    )\n",
    "\n",
    "    # Load Landsat\n",
    "    ds_ls, items_ls = pc_load(\n",
    "        product=\"landsat-c2-l2\",\n",
    "        bands=(\"green\", \"nir08\", \"qa_pixel\"),\n",
    "        stac_query={\n",
    "            \"eo:cloud_cover\": {\"lt\": cloud_cover},\n",
    "            \"platform\": {\"in\": [\"landsat-5\", \"landsat-8\", \"landsat-9\"]},\n",
    "            \"landsat:collection_category\": {\"in\": [\"T1\"]},\n",
    "        },\n",
    "        **query_params,\n",
    "        **load_params,\n",
    "    )\n",
    "\n",
    "    # Load Sentinel-2\n",
    "    ds_s2, items_s2 = pc_load(\n",
    "        product=\"sentinel-2-l2a\",\n",
    "        bands=(\"green\", \"nir\", \"SCL\"),\n",
    "        stac_query={\n",
    "            \"eo:cloud_cover\": {\"lt\": cloud_cover},\n",
    "        },\n",
    "        **query_params,\n",
    "        **load_params,\n",
    "    )\n",
    "\n",
    "    # Apply Landsat cloud mask\n",
    "    cloud_mask = (\n",
    "        # Bit 3: high confidence cloud, bit 4: high confidence shadow\n",
    "        # https://medium.com/analytics-vidhya/python-for-geosciences-\n",
    "        # raster-bit-masks-explained-step-by-step-8620ed27141e\n",
    "        np.bitwise_and(ds_ls.qa_pixel, 1 << 3)\n",
    "        | np.bitwise_and(ds_ls.qa_pixel, 1 << 4)\n",
    "    ) == 0\n",
    "    ds_ls = ds_ls.where(cloud_mask).drop(\"qa_pixel\")\n",
    "\n",
    "    # Apply Sentinel-2 cloud mask\n",
    "    # 1: defective, 3: shadow, 9: high confidence cloud\n",
    "    cloud_mask = ~ds_s2.SCL.isin([1, 3, 9])\n",
    "    ds_s2 = ds_s2.where(cloud_mask).drop(\"SCL\")\n",
    "\n",
    "    # Apply scaling\n",
    "    ds_ls = (ds_ls.where(ds_ls != 0) * 0.0000275 + -0.2).clip(0, 1)\n",
    "    ds_s2 = (ds_s2.where(ds_s2 != 0) * 0.0001).clip(0, 1)\n",
    "\n",
    "    # Convert to NDWI\n",
    "    ndwi_ls = (ds_ls.green - ds_ls.nir08) / (ds_ls.green + ds_ls.nir08)\n",
    "    ndwi_s2 = (ds_s2.green - ds_s2.nir) / (ds_s2.green + ds_s2.nir)\n",
    "\n",
    "    # Combine into a single dataset\n",
    "    satellite_ds = (\n",
    "        xr.concat([ndwi_ls, ndwi_s2], dim=\"time\").sortby(\"time\").to_dataset(name=\"ndwi\")\n",
    "    )\n",
    "\n",
    "    return satellite_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69b01f-bae0-4373-8ed6-e907393407eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02efd2f-dab6-41ec-86f0-1724c93cf356",
   "metadata": {},
   "source": [
    "### Set analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1dfca3-543d-4e07-9a0f-2eeddf582835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intertidal Elevation variables\n",
    "# config_path = \"configs/dea_intertidal_config.yaml\"\n",
    "# start_date = \"2020\"  # Start date for analysis\n",
    "# end_date = \"2022\"  # End date for analysis\n",
    "# resolution = 10  # Spatial resolution used for output files\n",
    "# crs = \"EPSG:3577\"  # Coordinate Reference System (CRS) to use for output files\n",
    "# ndwi_thresh = 0.1  # Threshold used to identify dry/wet transition\n",
    "# include_s2 = True  # Include Sentinel-2 data in the analysis?\n",
    "# include_ls = True  # Include Landsat data in the analysis?\n",
    "# filter_gqa = False  # Filter to remove poorly georeferenced scenes?\n",
    "# # tide_model = \"FES2014\"  # Tide model to use in analysis\n",
    "# # tide_model_dir = \"/var/share/tide_models\"  # Directory containing tide model files\n",
    "# # tide_model = \"FES2014\"\n",
    "# tide_model_dir = \"/gdata1/data/tide_models\"\n",
    "# tide_model = \"TPXO9-atlas-v5\"\n",
    "# # tide_model_dir = \"/home/jovyan/tide_models_clipped\"\n",
    "\n",
    "# Intertidal Elevation variables\n",
    "start_date = \"2020\"  # Start date for analysis\n",
    "end_date = \"2022\"  # End date for analysis\n",
    "resolution = 10  # Spatial resolution used for output files\n",
    "crs = \"EPSG:3577\"  # Coordinate Reference System (CRS) to use for output files\n",
    "ndwi_thresh = 0.1  # Threshold used to identify dry/wet transition\n",
    "include_s2 = True  # Include Sentinel-2 data in the analysis?\n",
    "include_ls = True  # Include Landsat data in the analysis?\n",
    "filter_gqa = True  # Filter to remove poorly georeferenced scenes?\n",
    "tide_model = \"EOT20\"  # Tide model to use in analysis \n",
    "# tide_model_dir = \"/var/share/tide_models\"  # Directory containing tide model files\n",
    "# tide_model = [\"FES2014\", \"FES2012\", \"TPXO9-atlas-v5\"]\n",
    "tide_model_dir = \"/gdata1/data/tide_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b72074d-c4bc-410b-83e1-80295227b81c",
   "metadata": {},
   "source": [
    "##### Load study area using interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf1c79-ae5a-4453-a7e8-d3f021b0b65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bc346f37e748a2a285ef906a25aae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-26, 135], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set study area name for outputs\n",
    "study_area = \"korea\"\n",
    "\n",
    "# Plot interactive map to select area\n",
    "basemap = basemap_to_tiles(basemaps.Esri.WorldImagery)\n",
    "geom = select_on_a_map(height=\"600px\", layers=(basemap,), center=(-26, 135), zoom=4)\n",
    "geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c892b8-42d3-4930-ad97-e0e214535fc5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8ec80-8f28-4127-b920-9fcf9fffb23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create local dask cluster to improve data load time\n",
    "client = create_local_dask_cluster(return_client=True)\n",
    "\n",
    "# Load data using odc-stac\n",
    "satellite_ds = load_ls_s2(\n",
    "    geom=geom,\n",
    "    resolution=resolution,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    cloud_cover=80,\n",
    ")\n",
    "print(satellite_ds)\n",
    "\n",
    "# Load data and close dask client\n",
    "satellite_ds.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34949eb-96f1-4844-ad6e-aeb71399e9f5",
   "metadata": {},
   "source": [
    "## Pixel-based tides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc505df-daf3-4592-858e-6695aa1f78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tides into every pixel in the three-dimensional (x by y by time) satellite dataset\n",
    "tide_m, _ = pixel_tides(\n",
    "    satellite_ds,\n",
    "    resample=True,\n",
    "    model=tide_model,\n",
    "    directory=tide_model_dir,\n",
    "    parallel_splits=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fcc597-9145-4f0e-bd4e-cef454d4a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experimental: testing ebb flow filtering\n",
    "# ebb_flow_da, tide_m_offset = pixel_ebb_flow(tide_m, offset_min=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcac52f-78d5-41f3-81a4-199509949a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tide array pixels to nodata if the satellite data array pixels contain\n",
    "# nodata. This ensures that we ignore any tide observations where we don't\n",
    "# have matching satellite imagery\n",
    "satellite_ds[\"tide_m\"] = tide_m.where(\n",
    "    ~satellite_ds.to_array().isel(variable=0).isnull().drop(\"variable\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c634b5-4195-4cee-9c34-84792debae03",
   "metadata": {},
   "source": [
    "## Pixel-based DEM creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197a187-6a74-4588-95ea-678a576a269b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Flatten array from 3D to 2D and drop pixels with no correlation with tide\n",
    "Flatten array to only pixels with positive correlations between water observations and tide height. This greatly improves processing time by ensuring only a narrow strip of pixels along the coastline are analysed, rather than the entire x * y array:\n",
    "\n",
    "\n",
    "![](../../data/figures/tide_array_flattening.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ee569-b862-4a4c-b04e-66b39c9fa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flat_ds, freq, corr = ds_to_flat(\n",
    "    satellite_ds,\n",
    "    ndwi_thresh=0.0,\n",
    "    min_freq=0.01,\n",
    "    max_freq=0.99,\n",
    "    min_correlation=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57e810-d4eb-4875-bf1a-aec1487acbf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pixel-wise rolling median\n",
    "This function performs a rolling median calculation along the tide heights of our satellite images. \n",
    "It breaks our tide range into `windows_n` individual rolling windows, each of which covers `windows_prop_tide` of the full tidal range. \n",
    "For each window, the function returns the median of all tide heights and NDWI index values within the window, and returns an array with a new \"interval\" dimension that summarises these values from low to high tide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e0556-c698-4628-b0f3-cf35e722a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_ds = pixel_rolling_median(\n",
    "    flat_ds,\n",
    "    windows_n=100,\n",
    "    window_prop_tide=0.15,\n",
    "    max_workers=None,\n",
    "    min_count=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab484a-b501-4203-88de-c8c959ae701c",
   "metadata": {},
   "source": [
    "### Model intertidal elevation and uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc468ab-9c95-4065-b0f4-ea323cff266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model elevation\n",
    "flat_dem = pixel_dem(\n",
    "    interval_ds,\n",
    "    ndwi_thresh=ndwi_thresh,\n",
    "    interp_intervals=200,\n",
    "    smooth_radius=20,\n",
    "    min_periods=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec14155-eeb5-4a78-a30f-54b329e6e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model uncertainty\n",
    "low, high, uncertainty, misclassified = pixel_uncertainty(\n",
    "    flat_ds, flat_dem, ndwi_thresh, method=\"mad\"\n",
    ")\n",
    "\n",
    "# Add arrays to dataset\n",
    "flat_dem[[\"elevation_low\", \"elevation_high\", \"elevation_uncertainty\"]] = (\n",
    "    low,\n",
    "    high,\n",
    "    uncertainty,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379f9cf-3f24-4a0f-9b37-e4b462dccb5d",
   "metadata": {},
   "source": [
    "## Unstack outputs and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d7d06-831b-43ed-8de9-7a29f2ca723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine QA layers with elevation layers\n",
    "flat_combined = xr.combine_by_coords(\n",
    "    [flat_dem,  # DEM data\n",
    "     freq,  # Frequency\n",
    "     corr,  # Correlation\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Unstack elevation and uncertainty layers back into their original \n",
    "# spatial dimensions\n",
    "ds = flat_to_ds(flat_combined, satellite_ds)\n",
    "\n",
    "# Clean upper edge of intertidal zone in elevation layers \n",
    "# (likely to be inaccurate edge pixels)\n",
    "elevation_bands = [d for d in ds.data_vars if \"elevation\" in d]\n",
    "ds[elevation_bands] = clean_edge_pixels(ds[elevation_bands])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace94ca-be78-4339-b01d-32f6162581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "ds.elevation.plot.imshow(cmap=\"viridis\", ax=axes[0])\n",
    "ds.elevation_uncertainty.plot.imshow(cmap=\"inferno\", ax=axes[1])\n",
    "ds.qa_ndwi_corr.plot.imshow(cmap=\"RdBu\", vmin=-0.7, vmax=0.7, ax=axes[2])\n",
    "ds.qa_ndwi_freq.plot.imshow(cmap=\"Blues\", vmin=0, vmax=1, ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccb4e3-4b04-499b-b9ff-1649c2d31c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.elevation.odc.explore(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd13e6-db3e-409c-905d-d9f6a9733348",
   "metadata": {},
   "source": [
    "### Export to GeoTIFF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296e76c-12b6-44bb-829b-871f955bbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "output_dir = f\"data/interim/{study_area}/{start_date}-{end_date}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Prepare data for export\n",
    "ds[\"qa_ndwi_freq\"] *= 100  # Convert frequency to %\n",
    "\n",
    "# Prepare for export by correctly setting nodata and dtypes, then\n",
    "# export to file\n",
    "ds_prepared = prepare_for_export(ds, output_location=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33dfdc-e687-4006-8be2-94f29c6948a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Close Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1f4b8-2941-42c5-8ccf-1b65c8a79acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
