{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d6b7a0-11bf-431f-b2dd-4d97c0cfb0a0",
   "metadata": {},
   "source": [
    "### Testing notebook to prototype exposure custom options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d85842-924e-47ac-a447-c985e979ab89",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Set working directory to top level of repo to ensure links work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8324d3-bb4b-42f8-ab51-c9f98f46f080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dea_intertidal/dea-intertidal\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2bb5f-4d03-450a-a9f1-f6ce93a6ccf6",
   "metadata": {},
   "source": [
    "Install additional packages directly from the requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7551ed6-1994-49d3-9300-0bc22fadb304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.in --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f8524-11cf-471b-ab4a-592d9e52b233",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88eada0-d3d1-4a80-a2d3-0f99519df8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sunriset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d19fac7-7637-4070-bde6-e63bcf3c9662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datacube\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from intertidal.utils import (\n",
    "    # load_config,\n",
    "    round_date_strings,\n",
    "    export_intertidal_rasters,\n",
    "    intertidal_hillshade,\n",
    ")\n",
    "# from intertidal.elevation import load_data, load_topobathy, elevation\n",
    "from intertidal.extents import extents\n",
    "from intertidal.exposure import exposure, exposure1\n",
    "from intertidal.tidal_bias_offset import bias_offset, tidal_offset_tidelines\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "\n",
    "## Temp for tide model testing 17/07/23\n",
    "from dea_tools.coastal import model_tides, pixel_tides\n",
    "\n",
    "\n",
    "# !pip install sunriset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546346c-fd91-46c8-bda9-bb22c8e94af7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Set analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efddd390-8797-4e3d-990e-454e685ef71b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##temp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m30h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m txt\u001b[38;5;241m.\u001b[39msplit(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m())\n\u001b[1;32m      7\u001b[0m x\n",
      "File \u001b[0;32m/env/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dir__\u001b[39m():\n\u001b[0;32m--> 324\u001b[0m     public_symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTester\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m    325\u001b[0m     public_symbols \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrixlib\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    327\u001b[0m     }\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(public_symbols)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "##temp\n",
    "\n",
    "txt = \"30h\"\n",
    "\n",
    "x = txt.split(np.int())\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21adcfb4-9ddb-4b5f-a2bf-3a878da08783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '30mi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m modelled_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m30min\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Frequency to run tidal model e.g '30T' for minutes or '1h' for hours \u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Extract the number of modelled timesteps per 14 days (half lunar cycle) for neap/spring calcs\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m mod_timesteps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(\u001b[38;5;241m14\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m/\u001b[39mpd\u001b[38;5;241m.\u001b[39mTimedelta(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodelled_freq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     27\u001b[0m                                                         modelled_freq\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Generate range of times covering entire period of satellite record for exposure and bias/offset calculation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m all_timerange \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(\n\u001b[1;32m     32\u001b[0m     start\u001b[38;5;241m=\u001b[39mround_date_strings(start_date, round_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     33\u001b[0m     end\u001b[38;5;241m=\u001b[39mround_date_strings(end_date, round_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     34\u001b[0m     freq\u001b[38;5;241m=\u001b[39mmodelled_freq,\n\u001b[1;32m     35\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '30mi'"
     ]
    }
   ],
   "source": [
    "# Intertidal Elevation variables\n",
    "start_date = \"2021\"  # Start date for analysis\n",
    "end_date = \"2021\"  # End date for analysis\n",
    "resolution = 2000  # Spatial resolution used for output files\n",
    "crs = \"EPSG:3577\"  # Coordinate Reference System (CRS) to use for output files\n",
    "ndwi_thresh = 0.1  # Threshold used to identify dry/wet transition when calculating elevation\n",
    "include_s2 = True  # Include Sentinel-2 data in the analysis?\n",
    "include_ls = True  # Include Landsat data in the analysis?\n",
    "filter_gqa = False  # Filter to remove poorly georeferenced scenes?\n",
    "tide_model = \"FES2014\"  # Tide model to use in analysis\n",
    "tide_model_dir = \"/gdata1/data/tide_models\"  #  Tide models on Sandbox sharedrive\n",
    "# tide_model_dir = \"/var/share/tide_models\"  # Directory containing tide model files\n",
    "# tide_model = [\"FES2014\", \"FES2012\", \"TPXO9-atlas-v5\"]\n",
    "# tide_model_dir = \"/gdata1/data/tide_models_clipped\"\n",
    "\n",
    "# Exposure variables\n",
    "# For pandas time aliases, see: https://pandas.pydata.org/docs/user_guide/timeseries.html#offset-aliases\n",
    "modelled_freq = \"30min\"  # Frequency to run tidal model e.g '30T' for minutes or '1h' for hours \n",
    "\n",
    "# Extract the number of modelled timesteps per 14 days (half lunar cycle) for neap/spring calcs\n",
    "mod_timesteps = pd.Timedelta(14,\"d\")/pd.Timedelta(int(modelled_freq.split()[0][:-1]),\n",
    "                                                        modelled_freq.split()[0][-1])\n",
    "\n",
    "\n",
    "# Generate range of times covering entire period of satellite record for exposure and bias/offset calculation\n",
    "all_timerange = pd.date_range(\n",
    "    start=round_date_strings(start_date, round_type=\"start\"),\n",
    "    end=round_date_strings(end_date, round_type=\"end\"),\n",
    "    freq=modelled_freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97320660-85cf-4949-82c4-a2b01fe482d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set study area and config\n",
    "study_area = \"gulfcarpentaria3\"\n",
    "config_path = \"configs/dea_intertidal_config_development.yaml\"\n",
    "# study_area = '844'\n",
    "# config_path='configs/dea_intertidal_config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a336b71-0d40-46f5-a213-4b2db4737c3b",
   "metadata": {},
   "source": [
    "#### *Optional: override study area selection using interactive map*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5108db11-a150-493a-9635-76d57c298fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from odc.ui import select_on_a_map\n",
    "# from ipyleaflet import basemaps, basemap_to_tiles\n",
    "\n",
    "# # Plot interactive map to select area\n",
    "# basemap = basemap_to_tiles(basemaps.Esri.WorldImagery)\n",
    "# geom = select_on_a_map(height='600px',\n",
    "#                        layers=(basemap,),\n",
    "#                        center=(-26, 135),\n",
    "#                        zoom=4)\n",
    "# study_area = geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d8f1b-5e02-4e71-a579-e5773cb0e3ed",
   "metadata": {},
   "source": [
    "## Intertidal workflow\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b902f104-0491-4cd9-b714-29449d6a06c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-1ced87f9-4bb2-11ee-8216-ee4f805b3ca3</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/claire.phillips@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/claire.phillips@ga.gov.au/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/claire.phillips@ga.gov.au/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">4aa4b7a3</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/user/claire.phillips@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/claire.phillips@ga.gov.au/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 1\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 31\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 237.21 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-68c73c0a-10f5-4d2d-adef-5042f9d58dfe</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:39981\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/claire.phillips@ga.gov.au/proxy/8787/status\" target=\"_blank\">/user/claire.phillips@ga.gov.au/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 31\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 237.21 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:44547\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 31\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/user/claire.phillips@ga.gov.au/proxy/45901/status\" target=\"_blank\">/user/claire.phillips@ga.gov.au/proxy/45901/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 237.21 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:39643\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-2o3jaeaa\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39981' processes=1 threads=31, memory=237.21 GiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.8/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _reproject(\n",
      "/env/lib/python3.8/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _reproject(\n"
     ]
    }
   ],
   "source": [
    "# Connect to datacube\n",
    "dc = datacube.Datacube(app=\"Intertidal_workflow\")\n",
    "\n",
    "# Create local dask cluster to improve data load time\n",
    "client = create_local_dask_cluster(return_client=True)\n",
    "\n",
    "satellite_ds = load_data(\n",
    "    dc=dc,\n",
    "    study_area=study_area,\n",
    "    time_range=(start_date, end_date),\n",
    "    resolution=resolution,\n",
    "    crs=crs,\n",
    "    s2_prod=\"s2_nbart_ndwi\" if include_s2 else None,\n",
    "    ls_prod=\"ls_nbart_ndwi\" if include_ls else None,\n",
    "    config_path=config_path,\n",
    "    filter_gqa=filter_gqa)[[\"ndwi\"]]\n",
    "\n",
    "# Load data and close dask client\n",
    "satellite_ds.load()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae8a1c-bba8-4e51-93bb-9429ca36ec6f",
   "metadata": {},
   "source": [
    "### Load optional topobathy mask\n",
    "Loads a topo-bathymetric DEM for the extents of the loaded satellite data.\n",
    "This is used as a coarse mask to constrain the analysis to the coastal zone, improving run time and reducing clear false positives over deep water or elevated land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65662f45-afc4-4636-9ed3-f37e2d4b3c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from GA's Australian Bathymetry and Topography Grid 2009\n",
    "topobathy_ds = load_topobathy(\n",
    "    dc, satellite_ds, product=\"ga_multi_ausbath_0\", resampling=\"bilinear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163b0f0-5431-43e7-ba8e-378bd991c084",
   "metadata": {},
   "source": [
    "### Intertidal elevation\n",
    "To run without the topobathy DEM mask, comment out `valid_mask=...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9bee00-cab0-43c8-8a4d-226dd5773ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 06:05:08 INFO Modelling tide heights for each pixel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating reduced resolution 5000 x 5000 metre tide modelling array\n",
      "Modelling tides with FES2014\n",
      "Reprojecting tides into original array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:00<00:00, 1244.62it/s]\n",
      "2023-09-05 06:06:07 INFO Masking nodata and adding tide heights to satellite data array\n",
      "INFO:DEA Intertidal:Masking nodata and adding tide heights to satellite data array\n",
      "2023-09-05 06:06:07 INFO Flattening satellite data array and filtering to intertidal candidate pixels\n",
      "INFO:DEA Intertidal:Flattening satellite data array and filtering to intertidal candidate pixels\n",
      "2023-09-05 06:06:07 INFO Applying valid data mask to constrain study area\n",
      "INFO:DEA Intertidal:Applying valid data mask to constrain study area\n",
      "2023-09-05 06:06:07 INFO Running per-pixel rolling median\n",
      "INFO:DEA Intertidal:Running per-pixel rolling median\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing analysed pixels from 25 to 8 (32.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 799.00it/s]\n",
      "2023-09-05 06:06:08 INFO Modelling intertidal elevation\n",
      "INFO:DEA Intertidal:Modelling intertidal elevation\n",
      "2023-09-05 06:06:08 INFO Modelling intertidal uncertainty\n",
      "INFO:DEA Intertidal:Modelling intertidal uncertainty\n",
      "2023-09-05 06:06:08 INFO Unflattening data back to its original spatial dimensions\n",
      "INFO:DEA Intertidal:Unflattening data back to its original spatial dimensions\n",
      "2023-09-05 06:06:08 INFO Successfully completed intertidal elevation modelling\n",
      "INFO:DEA Intertidal:Successfully completed intertidal elevation modelling\n"
     ]
    }
   ],
   "source": [
    "# Model elevation for each pixel\n",
    "ds, ds_aux, tide_m = elevation(\n",
    "    satellite_ds,\n",
    "    valid_mask=topobathy_ds.height_depth > -20,\n",
    "    tide_model=tide_model,\n",
    "    tide_model_dir=tide_model_dir,\n",
    "    config_path=config_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a26983-d98b-4d77-a603-183ad70a27d7",
   "metadata": {},
   "source": [
    "### Intertidal extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642ab47c-aff1-47cb-84e6-a3f884674d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds['extents'] = extents(ds_aux.ndwi_wet_freq, ds.elevation, ds_aux.ndwi_tide_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96203122-38b4-44d3-9ae1-1fbab0123537",
   "metadata": {},
   "source": [
    "### Intertidal exposure\n",
    "Calculate exposure using the script function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75483d43-64d8-490e-b58b-bfa7ce8ff2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds[\"exposure\"], tide_cq, _ = exposure(\n",
    "#     dem=ds.elevation,\n",
    "#     time_range=all_timerange,\n",
    "#     tide_model=tide_model,\n",
    "#     tide_model_dir=tide_model_dir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b88bf7-72ae-4132-9317-10a0d7d7c3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Testing updated script\n",
    "\n",
    "# # %reload_ext autoreload\n",
    "\n",
    "# ds[\"exposure_summer\"], tide_cq_summer, tiderange_summer = exposure(\n",
    "#     dem=ds.elevation,\n",
    "#     time_range=all_timerange,\n",
    "#     tide_model=tide_model,\n",
    "#     tide_model_dir=tide_model_dir,\n",
    "#     filters = ['summer']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0803444b-be0e-4907-986c-925f163ded85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timezones = {'wa':'../../gdata1/data/boundaries/GEODATA_COAST_100K/western_australia/cstwacd_r.shp',\n",
    "#                  'nt':'../../gdata1/data/boundaries/GEODATA_COAST_100K/northern_territory/cstntcd_r.shp',\n",
    "#                  'sa':'../../gdata1/data/boundaries/GEODATA_COAST_100K/south_australia/cstsacd_r.shp',\n",
    "#                  'qld':'../../gdata1/data/boundaries/GEODATA_COAST_100K/queensland/cstqldmd_r.shp',\n",
    "#                  'nsw':'../../gdata1/data/boundaries/GEODATA_COAST_100K/new_south_wales/cstnswcd_r.shp',\n",
    "#                  'vic':'../../gdata1/data/boundaries/GEODATA_COAST_100K/victoria/cstviccd_r.shp',\n",
    "#                  'tas':'../../gdata1/data/boundaries/GEODATA_COAST_100K/tasmania/csttascd_r.shp'\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16518326-6d4d-4373-b314-7b4557e4cd24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631862b0-c7bb-42a4-bf39-93c15271f79c",
   "metadata": {},
   "source": [
    "# Exposure\n",
    "\n",
    "## Choose from the following 'filters' - multiple selections supported\n",
    "\n",
    "dry, wet, summer, autumn, winter, spring, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec, Daylight, Night, Spring_high, Spring_low, Neap_high, Neap_low, Hightide, Lowtide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14d4391-39ac-4e1c-85f3-87a0198fd0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating reduced resolution 5000 x 5000 metre tide modelling array\n",
      "Modelling tides with FES2014\n",
      "Reprojecting tides into original array\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17473/17473 [00:10<00:00, 1736.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Spring_high\n",
      "Calculating Spring_low\n",
      "Calculating Neap_high\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex or align along dimension 'dim_0' because of conflicting dimension sizes: {532, 533, 534, 535, 536, 537, 538, 539}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %reload_ext autoreload\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m exposure, tide_cq, filt_dt \u001b[38;5;241m=\u001b[39m \u001b[43mexposure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melevation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtime_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_timerange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmod_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmod_timesteps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtide_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtide_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtide_model_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtide_model_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# 'dry', 'wet', 'summer', 'autumn', 'winter', \u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# 'spring', 'Jan', 'Feb', 'Mar', 'Apr', \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;66;43;03m# 'Dec', 'Daylight', 'Night',\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpring_high\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpring_low\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNeap_high\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNeap_low\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHightide\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLowtide\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dea_intertidal/dea-intertidal/intertidal/exposure.py:464\u001b[0m, in \u001b[0;36mexposure\u001b[0;34m(start_date, end_date, dem, time_range, mod_timesteps, tide_model, tide_model_dir, filters)\u001b[0m\n\u001b[1;32m    461\u001b[0m springhighs_all \u001b[38;5;241m=\u001b[39m stacked_everything_high\u001b[38;5;241m.\u001b[39munstack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m## apply the peak detection routine to calculate all the high tide maxima\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m Max_testarray \u001b[38;5;241m=\u001b[39m \u001b[43mstacked_everything\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43margrelmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m## extract the corresponding dates from the peaks\u001b[39;00m\n\u001b[1;32m    466\u001b[0m Max_testarray \u001b[38;5;241m=\u001b[39m (Max_testarray\u001b[38;5;241m.\u001b[39munstack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/groupby.py:1128\u001b[0m, in \u001b[0;36mDataArrayGroupByBase.apply\u001b[0;34m(self, func, shortcut, args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;124;03mBackward compatible implementation of ``map``\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03mDataArrayGroupBy.map\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupBy.apply may be deprecated in the future. Using GroupBy.map is encouraged\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1126\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1127\u001b[0m )\n\u001b[0;32m-> 1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/groupby.py:1113\u001b[0m, in \u001b[0;36mDataArrayGroupByBase.map\u001b[0;34m(self, func, args, shortcut, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m grouped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped_shortcut() \u001b[38;5;28;01mif\u001b[39;00m shortcut \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped()\n\u001b[1;32m   1112\u001b[0m applied \u001b[38;5;241m=\u001b[39m (maybe_wrap_array(arr, func(arr, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m grouped)\n\u001b[0;32m-> 1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapplied\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortcut\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/groupby.py:1137\u001b[0m, in \u001b[0;36mDataArrayGroupByBase._combine\u001b[0;34m(self, applied, shortcut)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concat_shortcut(applied, dim, positions)\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1137\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapplied\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1138\u001b[0m     combined \u001b[38;5;241m=\u001b[39m _maybe_reorder(combined, dim, positions)\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(combined, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj)):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;66;03m# only restore dimension order for arrays\u001b[39;00m\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/concat.py:236\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompat\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m invalid: must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_equals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_conflicts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, DataArray):\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dataarray_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, Dataset):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataset_concat(\n\u001b[1;32m    249\u001b[0m         objs,\n\u001b[1;32m    250\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    258\u001b[0m     )\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/concat.py:662\u001b[0m, in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    659\u001b[0m             arr \u001b[38;5;241m=\u001b[39m cast(T_DataArray, arr\u001b[38;5;241m.\u001b[39mrename(name))\n\u001b[1;32m    660\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mappend(arr\u001b[38;5;241m.\u001b[39m_to_temp_dataset())\n\u001b[0;32m--> 662\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_dataset_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m merged_attrs \u001b[38;5;241m=\u001b[39m merge_attrs([da\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;28;01mfor\u001b[39;00m da \u001b[38;5;129;01min\u001b[39;00m arrays], combine_attrs)\n\u001b[1;32m    676\u001b[0m result \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds, name)\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/concat.py:471\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Make sure we're working on a copy (we'll be loading variables)\u001b[39;00m\n\u001b[1;32m    469\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [ds\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m    470\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m--> 471\u001b[0m     \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m )\n\u001b[1;32m    474\u001b[0m dim_coords, dims_sizes, coord_names, data_names \u001b[38;5;241m=\u001b[39m _parse_datasets(datasets)\n\u001b[1;32m    475\u001b[0m dim_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(dim_coords)\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/alignment.py:797\u001b[0m, in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03mGiven any number of Dataset and/or DataArray objects, returns new\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mobjects with aligned indexes and dimension sizes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m \n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    789\u001b[0m aligner \u001b[38;5;241m=\u001b[39m Aligner(\n\u001b[1;32m    790\u001b[0m     objects,\n\u001b[1;32m    791\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    796\u001b[0m )\n\u001b[0;32m--> 797\u001b[0m \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligner\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/alignment.py:585\u001b[0m, in \u001b[0;36mAligner.align\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_no_index_conflict()\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_indexes()\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_unindexed_dim_sizes_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_indexes()\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/xarray/core/alignment.py:484\u001b[0m, in \u001b[0;36mAligner.assert_unindexed_dim_sizes_equal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m     add_err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sizes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex or align along dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause of conflicting dimension sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m add_err_msg\n\u001b[1;32m    487\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex or align along dimension 'dim_0' because of conflicting dimension sizes: {532, 533, 534, 535, 536, 537, 538, 539}"
     ]
    }
   ],
   "source": [
    "# %reload_ext autoreload\n",
    "\n",
    "exposure, tide_cq, filt_dt = exposure(\n",
    "                            start_date,\n",
    "                            end_date,\n",
    "                            dem=ds.elevation,\n",
    "                            time_range=all_timerange,\n",
    "                            mod_timesteps=[mod_timesteps],\n",
    "                            tide_model=tide_model,\n",
    "                            tide_model_dir=tide_model_dir,\n",
    "                            filters = [\n",
    "                                       # 'dry', 'wet', 'summer', 'autumn', 'winter', \n",
    "                                       # 'spring', 'Jan', 'Feb', 'Mar', 'Apr', \n",
    "                                       # 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', \n",
    "                                       # 'Dec', 'Daylight', 'Night',\n",
    "                                       'Spring_high', 'Spring_low', 'Neap_high', 'Neap_low', \n",
    "                                       'Hightide', 'Lowtide']\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f990d-cc37-4330-9ff1-339b4c7f7af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filt_dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778282b-a21a-46e7-abe2-f2708da04995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "filt_dt['modelledtides'][0].isel(y=1,x=1).plot()#marker='o', linestyle='')\n",
    "filt_dt['springhighs_all'].isel(y=1,x=1).plot()\n",
    "filt_dt['springlows_all'].isel(y=1,x=1).plot()\n",
    "filt_dt['neaphighs_all'].isel(y=1,x=1).plot()\n",
    "filt_dt['neaplows_all'].isel(y=1,x=1).plot()\n",
    "filt_dt['hightides'].isel(y=1,x=1).plot()\n",
    "filt_dt['lowtides'].isel(y=1,x=1).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae74e39-1b25-4ac1-8429-be0c90f2da2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "filt_dt['modelledtides'][0][0:1500].isel(y=1,x=1).plot()#marker='o', linestyle='')\n",
    "filt_dt['springhighs_all'][0:2].isel(y=1,x=1).plot()\n",
    "filt_dt['springlows_all'][0:2].isel(y=1,x=1).plot()\n",
    "filt_dt['neaphighs_all'][0:2].isel(y=1,x=1).plot()\n",
    "filt_dt['neaplows_all'][0:2].isel(y=1,x=1).plot()\n",
    "filt_dt['hightides'][0:180].isel(y=1,x=1).plot(marker='o', linestyle='')\n",
    "filt_dt['lowtides'][0:180].isel(y=1,x=1).plot(marker='o', linestyle='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc648a-dcc4-4831-ac15-9557358e6b67",
   "metadata": {},
   "source": [
    "## Spatial testing of peak detection on tidal modelling\n",
    "[Tidal regime and ranges](http://gyre.umeoce.maine.edu/physicalocean/Tomczak/ShelfCoast/notes/figures/fig18a1.html)\n",
    "\n",
    "|study area | tidal regime|tidal range| exposure spatial modelling behaved?|\n",
    "|---|---|---|---|\n",
    "|carnot WA|semi-diurnal| 4-8 m| yes|\n",
    "|yawajaba WA| semi-diurnal| >8m| reasonably good. Some hightide and lowtide peaks were not captured at 3hr interval but fine at 30min|\n",
    "|gulfcarpentaria3| mixed-diurnal|2-4 m||\n",
    "|gulfcarpentaria1| mixed| 2-4 m||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dccb8-12b8-45a7-b81e-f62b7dac61d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tide_cq\n",
    "exposure.hightide_exp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68dc94-e561-48e6-86ce-269836f562fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exposure.lowtide_exp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd68a0-8d98-4fb2-b2aa-c478f6cddbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "de = dry_exposure.to_dataset().rename_vars({'quantile':'dry_exposure'})\n",
    "de#['quantile'].plot()#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333979e-68af-496d-a51e-06284c11fafd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdbee0-0eee-444e-98a8-d0a0934fb8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = xr.merge([ds,de])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dd9d6-e32e-4a99-bf70-57b0bf000662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8b6ce-5017-4330-b24a-658e66a66334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff586210-5e5d-43c2-94a2-4ecb348040c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from scipy.signal import argrelmax \n",
    "from scipy.signal import argrelmin \n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0b320-f8fb-4f5c-850b-5d7edaef3370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run a full tidal model for each pixel\n",
    "modelledtides = pixel_tides(\n",
    "                            ds.elevation,#ds,\n",
    "                            times=all_timerange,\n",
    "                            model=tide_model,\n",
    "                            directory = tide_model_dir)\n",
    "## stack the y and x dimensions\n",
    "stacked_everything = modelledtides[0].stack(z=['y','x']).groupby('z') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92ec04-7e76-4413-a18d-a543bfe56a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order=(int([mod_timesteps][0]/2))\n",
    "\n",
    "stacked_everything_high = stacked_everything.apply(lambda x: xr.DataArray(argrelmax(x.values, order=order)[0]))\n",
    "\n",
    "## Unstack\n",
    "springhighs_all = stacked_everything_high.unstack('z')\n",
    "\n",
    "# order = int(ceil((len(Max_testarray.time)/(len(springhighs_all.time))/2)))\n",
    "# print(springhighs_all.time)\n",
    "springhighs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a1c82-625f-4ba0-96d2-5e7a5962aca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(springhighs_all)\n",
    "# print(springhighs_all.tide_m)\n",
    "all_timerange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c04a9-b23a-499a-8070-a76ed4baec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Calculating Spring_high')\n",
    "\n",
    "## apply the peak detection routine\n",
    "# stacked_everything_high = stacked_everything.apply(lambda x: xr.DataArray(argrelmax(x.values, order=order)[0]))\n",
    "# ## Unstack\n",
    "# springhighs_all = stacked_everything_high.unstack('z')\n",
    "# ##Reorder the y axis. Uncertain why it gets reversed during the stack/unstack.\n",
    "springhighs_all = springhighs_all.reindex(y=springhighs_all.y[::-1])\n",
    "## Rename the time axis\n",
    "springhighs_all = springhighs_all.rename({'dim_0':'time'})\n",
    "## Convert to dataset\n",
    "springhighs_all = springhighs_all.to_dataset(name = 'time')\n",
    "## Reorder the dims\n",
    "springhighs_all = springhighs_all[['time','y','x']]\n",
    "## Select dates associated with detected peaks\n",
    "springhighs_all = ModelledTides[0].to_dataset().isel(time=springhighs_all.time)\n",
    "## Extract the peak height dates\n",
    "# time_range = test_mt[springhighs].time.values\n",
    "\n",
    "## Temp: for tide-regime testing\n",
    "filt_dt['springhighs_all']=springhighs_all.tide_m\n",
    "\n",
    "tide_cq = springhighs_all.tide_m.quantile(q=calculate_quantiles,dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272ca44-7dbc-4698-a7bc-8715eedce390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5655b-aa1a-4660-af7f-df3eb7ffbc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267131a0-4446-43e6-a936-90b38c01a341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.dry_exposure.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a70ca-6226-4132-9408-5f8142f8ab24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds.nwet_exposure.plot()\n",
    "\n",
    "# blank = None\n",
    "# blankety = [0,1,3]\n",
    "\n",
    "# if blank is not None:\n",
    "#     print ('not none')\n",
    "#     for x in blank:\n",
    "#         if x in blankety:\n",
    "#             if x == 1:\n",
    "#                 print ('1')\n",
    "# else:\n",
    "#     print ('none')\n",
    "np.timedelta64(14,'D') / np.timedelta64(modelled_freq.split()[0][:-1],modelled_freq.split()[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832deab2-e465-45ed-9517-e66baff9cc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Testing cell\n",
    "\n",
    "# ## Bring in the geodata coast 100K polygons to assign local timezones to pixels\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import xarray as xr\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.ops import unary_union\n",
    "# import sunriset\n",
    "# from math import ceil\n",
    "# import datetime\n",
    "# from datetime import timedelta\n",
    "# import pytz\n",
    "# from pyproj import CRS\n",
    "# from pyproj import Transformer\n",
    "\n",
    "# ds.elevation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fa97f-af1b-4f45-9ec9-2384007f4e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create output folder. If it doesn't exist, create it\n",
    "output_dir = f\"data/interim/{study_area}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save rasters as GeoTIFFs\n",
    "export_intertidal_rasters(ds, prefix=f\"{output_dir}/{study_area}_{start_date}_{end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f521a-f210-49dc-abe3-9194b6fb2cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Bring in the state polygons (note: native crs = epsg:4283)\n",
    "# wa = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/western_australia/cstwacd_r.shp')\n",
    "# nt = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/northern_territory/cstntcd_r.shp')\n",
    "# sa = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/south_australia/cstsacd_r.shp')\n",
    "# qld = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/queensland/cstqldmd_r.shp')\n",
    "# nsw = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/new_south_wales/cstnswcd_r.shp')\n",
    "# vic = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/victoria/cstviccd_r.shp')\n",
    "# tas = gpd.read_file('../../gdata1/data/boundaries/GEODATA_COAST_100K/tasmania/csttascd_r.shp')\n",
    "\n",
    "# # Merge to create single timezone (state) boundaries\n",
    "# wa = gpd.GeoSeries(unary_union(wa.geometry))\n",
    "# nt = gpd.GeoSeries(unary_union(nt.geometry))\n",
    "# sa = gpd.GeoSeries(unary_union(sa.geometry))\n",
    "# qld = gpd.GeoSeries(unary_union(qld.geometry))\n",
    "# nsw = gpd.GeoSeries(unary_union(nsw.geometry))\n",
    "# vic = gpd.GeoSeries(unary_union(vic.geometry))\n",
    "# tas = gpd.GeoSeries(unary_union(tas.geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a46b7-a9c0-4fb5-8c2a-b5b494a4c492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Transform the analysis aoi coords to common CRS\n",
    "\n",
    "# tidepost_lat_3577 = ds.x.median(dim='x').values\n",
    "# tidepost_lon_3577 = ds.y.median(dim='y').values\n",
    "\n",
    "# ## Datacube native CRS\n",
    "# crs_3577 = CRS.from_epsg(3577) \n",
    "\n",
    "# ## GDA94/Aus Albers (meters)\n",
    "\n",
    "# ## Create a transform to convert default epsg3577 coords to epsg4326 for use in sunise/sunset library\n",
    "\n",
    "# ## World WGS84 (degrees)\n",
    "# crs_4326 = CRS.from_epsg(4326) \n",
    "# ## Transfer coords from/to\n",
    "# transformer_4326 = Transformer.from_crs(crs_3577, crs_4326)\n",
    "# ## Translate the tidepost coords\n",
    "# tidepost_lat_4326, tidepost_lon_4326 = transformer_4326.transform(tidepost_lat_3577, tidepost_lon_3577)\n",
    "# ## Coordinate point to locate the sunriset calculation\n",
    "# point_4326 = Point(tidepost_lon_4326, tidepost_lat_4326)\n",
    "\n",
    "# ## (1) Create a transform to convert default epsg3577 coords to epsg4283 to compare against polygons and \n",
    "# ## assign a timezone\n",
    "\n",
    "# ## GDA94 CRS (degrees)\n",
    "# crs_4283 = CRS.from_epsg(4283) ## GDA94 Australia (degrees)\n",
    "# ## Transfer coords from/to\n",
    "# transformer_4283 = Transformer.from_crs(crs_3577, crs_4283) \n",
    "# ## Translate tidepost coords\n",
    "# tidepost_lat_4283, tidepost_lon_4283 = transformer_4283.transform(tidepost_lat_3577, tidepost_lon_3577)\n",
    "# ## Coordinate point to test for timezone   \n",
    "# point_4283 = Point(tidepost_lon_4283, tidepost_lat_4283)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec620a0-ff7b-43de-ba73-b99b3e7b372f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Set the local timezone for the analysis area of interest\n",
    "# if wa.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/West'\n",
    "#     local_tz = 8\n",
    "#     # break\n",
    "# elif nt.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/North'\n",
    "#     local_tz = 9.5\n",
    "#     # break\n",
    "# elif sa.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/South'\n",
    "#     local_tz = 9.5\n",
    "#     # break\n",
    "# elif qld.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/Queensland'\n",
    "#     local_tz = 10\n",
    "#     # break\n",
    "# elif nsw.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/NSW'\n",
    "#     local_tz = 10\n",
    "#     # break\n",
    "# elif vic.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/Victoria'\n",
    "#     local_tz = 10\n",
    "#     # break\n",
    "# elif tas.contains(point_4283)[0] == True:\n",
    "#     timezone = 'Australia/Tasmania'\n",
    "#     local_tz = 10\n",
    "#     # break\n",
    "# print (timezone, local_tz)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1899c68-869a-4a34-ab04-844f0c93dcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Testing sunriset calculations\n",
    "\n",
    "# # Place start and end dates in correct format\n",
    "# start=round_date_strings(start_date, round_type=\"start\")\n",
    "# end=round_date_strings(end_date, round_type=\"end\")\n",
    "# startdate = datetime.date(pd.to_datetime(start).year, pd.to_datetime(start).month, pd.to_datetime(start).day)\n",
    "\n",
    "# # # Make the start date timezone aware \n",
    "# # time_start = pd.to_datetime(start, utc=True).tz_convert(timezone)\n",
    "\n",
    "# # Make 'all_timerange' time-zone aware\n",
    "# localtides = all_timerange.tz_localize(tz=pytz.UTC).tz_convert(timezone)\n",
    "\n",
    "# # Replace the UTC datetimes from all_timerange with local times\n",
    "# modelledtides = pd.DataFrame(index = localtides)\n",
    "\n",
    "# # Return the difference in years for the time-period. \n",
    "# # Round up to ensure all modelledtide datetimes are captured in the solar model\n",
    "# diff = pd.to_datetime(end) - pd.to_datetime(start)\n",
    "# diff = int(ceil(diff.days/365))\n",
    "\n",
    "# # ## Locate the central pixel for the area of interest\n",
    "# # ## TODO: work out how to manage this in the pixel-based workflow. Perhaps\n",
    "# # ## use the same modelling resolution as the underlying tidal model?\n",
    "# # tidepost_lat = ds.x.median(dim='x')\n",
    "# # tidepost_lon = ds.y.median(dim='y')\n",
    "\n",
    "# # ## Create a transform to convert default epsg3577 coords to epsg4326 for use in sunise/sunset library\n",
    "# # crs_4326 = CRS.from_epsg(4326)\n",
    "# # crs_3577 = CRS.from_epsg(3577)\n",
    "\n",
    "# # transformer = Transformer.from_crs(crs_3577, crs_4326)\n",
    "\n",
    "# # ## Translate tidepost coords\n",
    "# # tidepost_lat, tidepost_lon = transformer.transform(tidepost_lon.values, tidepost_lat.values)\n",
    "\n",
    "# ## Model sunrise and sunset\n",
    "# sun_df = sunriset.to_pandas(startdate, tidepost_lat_4326, tidepost_lon_4326, local_tz, diff)\n",
    "\n",
    "# ## Set the index as a datetimeindex to match the modelledtide df\n",
    "# sun_df = sun_df.set_index(pd.DatetimeIndex(sun_df.index))\n",
    "\n",
    "# ## Append the date to each Sunrise and Sunset time\n",
    "# sun_df['Sunrise dt'] = sun_df.index + sun_df['Sunrise']\n",
    "# sun_df['Sunset dt'] = sun_df.index + (sun_df['Sunset'])\n",
    "\n",
    "# ## Create new dataframes where daytime and nightime datetimes are recorded, then merged on a new `Sunlight` column\n",
    "# daytime=pd.DataFrame(data = 'Sunrise', index=sun_df['Sunrise dt'], columns=['Sunlight'])\n",
    "# nighttime=pd.DataFrame(data = 'Sunset', index=sun_df['Sunset dt'], columns=['Sunlight'])\n",
    "# DayNight = pd.concat([daytime, nighttime], join='outer')\n",
    "# DayNight.sort_index(inplace=True)\n",
    "# DayNight.index.rename('Datetime', inplace=True)\n",
    "\n",
    "# ## Create an xarray object from the merged day/night dataframe\n",
    "# day_night = xr.Dataset.from_dataframe(DayNight)\n",
    "\n",
    "# ## Remove local timezone timestamp column in modelledtides dataframe. Xarray doesn't handle \n",
    "# ## timezone aware datetimeindexes 'from_dataframe' very well.\n",
    "# modelledtides.index = modelledtides.index.tz_localize(tz=None)\n",
    "\n",
    "# ## Create an xr Dataset from the modelledtides pd.dataframe\n",
    "# mt = modelledtides.to_xarray()\n",
    "\n",
    "# ## Filter the modelledtides (mt) by the daytime, nighttime datetimes from the sunriset module\n",
    "# ## Modelled tides are designated as either day or night by propogation of the last valid index value forward\n",
    "# Solar=day_night.sel(Datetime=mt.index, method='ffill')\n",
    "\n",
    "# ## Assign the day and night tideheight datasets\n",
    "# SolarDayTides = mt.where(Solar.Sunlight=='Sunrise', drop=True)\n",
    "# SolarNightTides = mt.where(Solar.Sunlight=='Sunset', drop=True)\n",
    "\n",
    "# ## Extract DatetimeIndexes to use in exposure calculations\n",
    "# all_timerange_day = pd.DatetimeIndex(SolarDayTides.index)\n",
    "# all_timerange_night = pd.DatetimeIndex(SolarNightTides.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367ec88-d8b2-43a2-9004-58d032a3e929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.exposure_daylight.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026e4ed-4936-4d96-87bb-ed4c44bff01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.elevation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a845a7-b544-44f5-b85d-f8354282308d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dea_tools.coastal import model_tides, pixel_tides\n",
    "\n",
    "from scipy.signal import argrelmax \n",
    "from scipy.signal import argrelmin \n",
    "from scipy.interpolate import interp1d \n",
    "import xarray as xr\n",
    "\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351a0a3-30ce-4d11-b329-40587b98b9b1",
   "metadata": {},
   "source": [
    "## filters can be any of\n",
    "Spring_high, Spring_low, Neap_high, Neap_low, Hightide, Lowtide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d548e-eebf-431a-8c8f-2ea40adadae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Testing for spatial customisation (splicing up the tidal zone)\n",
    "\n",
    "modelledtides = pixel_tides(\n",
    "                ds,\n",
    "                times=all_timerange,\n",
    "                model=tide_model,\n",
    "                directory = tide_model_dir)\n",
    "                # directory = '../../gdata1/data/tide_models')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225a9bb-ffc4-42eb-bf60-a0a0b49522f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds\n",
    "type(modelled_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d31e5-25e2-4c3c-bfc0-8adf03a9d361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Peak selections in xarray for whole arrays\n",
    "## Calculations for Spring/Neap/High/Low tides\n",
    "## Hardcoded assumption: one spring high tide per 14 day half-lunar cycle\n",
    "test_filters = ['Lowtide', 'Hightide']#'Spring_low', 'Neap_low']#'Lowtide','Spring_high','Hightide','Neap_high'] # 'Spring_high' must run by default as its outputs are required for neap tide detection\n",
    "# Extract the modelling freq units\n",
    "freq_unit = modelled_freq.split()[0][-1]\n",
    "freq_value = modelled_freq.split()[0][:-1]\n",
    "# Extract the number of modelled timesteps per 14 days\n",
    "mod_timesteps = np.timedelta64(14,'D') / np.timedelta64(freq_value,freq_unit)\n",
    "## Identify kwargs for peak detection algorithm\n",
    "order=(int(mod_timesteps/2))\n",
    "\n",
    "## stack the y and x dimensions\n",
    "stacked_everything = modelledtides[0].stack(z=['y','x']).groupby('z') \n",
    "\n",
    "## Calculate the spring highest and spring lowest tides per 14 day half lunar cycle\n",
    "if 'Spring_high' in test_filters:\n",
    "    # ## stack the y and x dimensions\n",
    "    # stacked_everything = modelledtides[0].stack(z=['y','x']).groupby('z') \n",
    "    ## apply the peak detection routine\n",
    "    stacked_everything = stacked_everything.apply(lambda x: xr.DataArray(argrelmax(x.values, order=order)[0]))\n",
    "    ## Unstack\n",
    "    springhighs_all = stacked_everything.unstack('z')\n",
    "    ##Reorder the y axis. Uncertain why it gets reversed during the stack/unstack.\n",
    "    springhighs_all = springhighs_all.reindex(y=springhighs_all.y[::-1])\n",
    "    ## Rename the time axis\n",
    "    springhighs_all = springhighs_all.rename({'dim_0':'time'})\n",
    "    ## Convert to dataset\n",
    "    springhighs_all = springhighs_all.to_dataset(name = 'time')\n",
    "    ## Reorder the dims\n",
    "    springhighs_all = springhighs_all[['time','y','x']]\n",
    "    ## Select dates associated with detected peaks\n",
    "    springhighs_all = modelledtides[0].to_dataset().isel(time=springhighs_all.time)\n",
    "    ## Extract the peak height dates\n",
    "    # time_range = test_mt[springhighs].time.values\n",
    "\n",
    "    ## Calculate the spring highest and spring lowest tides per 14 day half lunar cycle\n",
    "if 'Spring_low' in test_filters:\n",
    "    ## apply the peak detection routine\n",
    "    stacked_everything = stacked_everything.apply(lambda x: xr.DataArray(argrelmin(x.values, order=order)[0]))\n",
    "    ## Unstack\n",
    "    springlows_all = stacked_everything.unstack('z')\n",
    "    ##Reorder the y axis. Uncertain why it gets reversed during the stack/unstack.\n",
    "    springlows_all = springlows_all.reindex(y=springlows_all.y[::-1])\n",
    "    ## Rename the time axis\n",
    "    springlows_all = springlows_all.rename({'dim_0':'time'})\n",
    "    ## Convert to dataset\n",
    "    springlows_all = springlows_all.to_dataset(name = 'time')\n",
    "    ## Reorder the dims\n",
    "    springlows_all = springlows_all[['time','y','x']]\n",
    "    ## Select dates associated with detected peaks\n",
    "    springlows_all = modelledtides[0].to_dataset().isel(time=springlows_all.time)\n",
    "    ## Extract the peak height dates\n",
    "    # time_range = test_mt[springlows_all].time.values\n",
    "    \n",
    "if 'Neap_high' in test_filters:\n",
    "    # ## stack the y and x dimensions\n",
    "    # stacked_everything = modelledtides[0].stack(z=['y','x']).groupby('z') \n",
    "    ## apply the peak detection routine to calculate all the high tide maxima\n",
    "    Max_testarray = stacked_everything.apply(lambda x: xr.DataArray(argrelmax(x.values)[0]))\n",
    "    ## extract the corresponding dates from the peaks\n",
    "    Max_testarray = (Max_testarray.unstack('z'))\n",
    "    Max_testarray = (Max_testarray.reindex(y=Max_testarray.y[::-1])\n",
    "                     .rename({'dim_0':'time'})\n",
    "                     .to_dataset(name = 'time')\n",
    "                     [['time','y','x']]\n",
    "                    )\n",
    "    ## extract all hightide peaks\n",
    "    Max_testarray = modelledtides[0].to_dataset().isel(time=Max_testarray.time)\n",
    "    \n",
    "    ## repeat the peak detection to identify neap high tides (minima in the high tide maxima)\n",
    "    stacked_everything2 = Max_testarray.tide_m.stack(z=['y','x']).groupby('z')\n",
    "    ## extract neap high tides based on 14 day half lunar cycle - determined as the fraction of all high tide points\n",
    "    ## relative to the number of spring high tide values\n",
    "    order = int(ceil((len(Max_testarray.time)/(len(springhighs_all.time))/2)))\n",
    "    ## apply the peak detection routine to calculate all the neap high tide minima within the high tide peaks\n",
    "    neaphighs_all = stacked_everything2.apply(lambda x: xr.DataArray(argrelmin(x.values, order=order)[0]))\n",
    "    ## unstack and format as above                                    \n",
    "    neaphighs_all = neaphighs_all.unstack('z')\n",
    "    neaphighs_all = (\n",
    "                    neaphighs_all\n",
    "                     .reindex(y=neaphighs_all.y[::-1])\n",
    "                     .rename({'dim_0':'time'})\n",
    "                     .to_dataset(name = 'time')\n",
    "                     [['time','y','x']]\n",
    "                    )\n",
    "    ## extract neap high tides\n",
    "    neaphighs_all = Max_testarray.isel(time=neaphighs_all.time)\n",
    "    \n",
    "if 'Neap_low' in test_filters:\n",
    "    # ## stack the y and x dimensions\n",
    "    # stacked_everything = modelledtides[0].stack(z=['y','x']).groupby('z') \n",
    "    ## apply the peak detection routine to calculate all the high tide maxima\n",
    "    Max_testarray = stacked_everything.apply(lambda x: xr.DataArray(argrelmax(x.values)[0]))\n",
    "    ## extract the corresponding dates from the peaks\n",
    "    Max_testarray = (Max_testarray.unstack('z'))\n",
    "    Max_testarray = (Max_testarray.reindex(y=Max_testarray.y[::-1])\n",
    "                     .rename({'dim_0':'time'})\n",
    "                     .to_dataset(name = 'time')\n",
    "                     [['time','y','x']]\n",
    "                    )\n",
    "    ## extract all hightide peaks\n",
    "    Max_testarray = modelledtides[0].to_dataset().isel(time=Max_testarray.time)\n",
    "    \n",
    "    ## repeat the peak detection to identify neap high tides (minima in the high tide maxima)\n",
    "    stacked_everything2 = Max_testarray.tide_m.stack(z=['y','x']).groupby('z')\n",
    "    ## extract neap high tides based on 14 day half lunar cycle - determined as the fraction of all high tide points\n",
    "    ## relative to the number of spring high tide values\n",
    "    order = int(ceil((len(Max_testarray.time)/(len(springhighs_all.time))/2)))\n",
    "    ## apply the peak detection routine to calculate all the neap high tide minima within the high tide peaks\n",
    "    neaphighs_all = stacked_everything2.apply(lambda x: xr.DataArray(argrelmin(x.values, order=order)[0]))\n",
    "    ## unstack and format as above                                    \n",
    "    neaphighs_all = neaphighs_all.unstack('z')\n",
    "    neaphighs_all = (\n",
    "                    neaphighs_all\n",
    "                     .reindex(y=neaphighs_all.y[::-1])\n",
    "                     .rename({'dim_0':'time'})\n",
    "                     .to_dataset(name = 'time')\n",
    "                     [['time','y','x']]\n",
    "                    )\n",
    "    ## extract neap high tides\n",
    "    neaphighs_all = Max_testarray.isel(time=neaphighs_all.time)\n",
    "    \n",
    "if 'Hightide' in test_filters:\n",
    "    def lowesthightides(x):\n",
    "        '''\n",
    "        x is a grouping of x and y pixels from the peaks_array (labelled as 'z')\n",
    "        '''\n",
    "\n",
    "        ## apply the peak detection routine to calculate all the high tide maxima\n",
    "        high_peaks = np.array(argrelmax(x.values)[0])\n",
    "\n",
    "        ## extract all hightide peaks\n",
    "        Max_testarray = x.isel(time=high_peaks)\n",
    "\n",
    "        ## Identify all lower hightide peaks\n",
    "        lowhigh_peaks = np.array(argrelmin(Max_testarray.values)[0])\n",
    "\n",
    "        ## Interpolate the lower hightide curve\n",
    "        neap_high_linear = interp1d(\n",
    "                                    ## low high peaks as a subset of all high tide peaks\n",
    "                                    high_peaks[lowhigh_peaks],\n",
    "                                    ## Corresponding tide heights\n",
    "                                    Max_testarray.isel(time=lowhigh_peaks).squeeze(['z']).values,\n",
    "                                    kind='linear', \n",
    "                                    fill_value='extrapolate'\n",
    "                                    )\n",
    "        ## Create an array to interpolate into sans datetimes\n",
    "        count = np.arange(0,len(x),1)\n",
    "        neap_high_testline = neap_high_linear(count)\n",
    "\n",
    "        # # Extract hightides as all tides higher than/equal to the extrapolated lowest high tide line\n",
    "        hightide = x.squeeze(['z']).where(x.squeeze(['z']) >= neap_high_testline, drop=True)\n",
    "\n",
    "        return hightide \n",
    "\n",
    "    ## Vectorise the hightide calculation\n",
    "    lowhighs_all = stacked_everything.apply(lambda x: xr.DataArray(lowesthightides(x)))\n",
    "\n",
    "    # ## Unstack and re-format the array\n",
    "    lowhighs_all = lowhighs_all.unstack('z')\n",
    "    lowhighs_all_unstacked = (\n",
    "                        lowhighs_all\n",
    "                         .reindex(y=lowhighs_all.y[::-1])\n",
    "                         # .rename({'dim_0':'time'})\n",
    "                         # .rename({'time':'hightide'})\n",
    "                         .to_dataset()#name = 'time')\n",
    "                         [['tide_m','time','y','x']]\n",
    "                        )\n",
    "\n",
    "    ## Calculate exposure using regular method\n",
    "    calculate_quantiles = np.linspace(0, 1, 101)#101)\n",
    "\n",
    "    tide_cq = lowhighs_all_unstacked.tide_m.quantile(q=calculate_quantiles,dim='time')\n",
    "\n",
    "    # Calculate the tide-height difference between the elevation value and\n",
    "    # each percentile value per pixel\n",
    "    diff = abs(tide_cq - ds.elevation)\n",
    "\n",
    "    # Take the percentile of the smallest tide-height difference as the\n",
    "    # exposure % per pixel\n",
    "    idxmin = diff.idxmin(dim=\"quantile\")\n",
    "\n",
    "    # Convert to percentage\n",
    "    hightide_exposure = idxmin * 100\n",
    "    \n",
    "    # return hightide_exposure\n",
    "\n",
    "if 'Lowtide' in test_filters:\n",
    "    def highestlowtides(x):\n",
    "        '''\n",
    "        x is a grouping of x and y pixels from the peaks_array (labelled as 'z')\n",
    "        '''\n",
    "\n",
    "        ## apply the peak detection routine to calculate all the high tide maxima\n",
    "        low_peaks = np.array(argrelmin(x.values)[0])\n",
    "\n",
    "        ## extract all hightide peaks\n",
    "        Min_testarray = x.isel(time=low_peaks)\n",
    "\n",
    "        ## Identify all lower hightide peaks\n",
    "        highlow_peaks = np.array(argrelmax(Min_testarray.values)[0])\n",
    "\n",
    "        ## Interpolate the lower hightide curve\n",
    "        neap_low_linear = interp1d(\n",
    "                                ## low high peaks as a subset of all high tide peaks\n",
    "                                low_peaks[highlow_peaks],\n",
    "                                ## Corresponding tide heights\n",
    "                                Min_testarray.isel(time=highlow_peaks).squeeze(['z']).values,\n",
    "                                # stacked_everything33, \n",
    "                                # stacked_everything333.isel(y=0,x=0), # z=0 in stacked arrays?\n",
    "                                # stacked_everything333,#.isel(z=x), # z=0 in stacked arrays?\n",
    "                                # stacked_everything333.squeeze(['z']).values,\n",
    "                                bounds_error=False, \n",
    "                                kind='linear', \n",
    "                                fill_value='extrapolate'\n",
    "                              )\n",
    "        ## Create an array to interpolate into sans datetimes\n",
    "        count = np.arange(0,len(x),1)\n",
    "        neap_low_testline = neap_low_linear(count)\n",
    "\n",
    "        # # Extract hightides as all tides higher than/equal to the extrapolated lowest high tide line\n",
    "        lowtide = x.squeeze(['z']).where(x.squeeze(['z']) >= neap_low_testline, drop=True)\n",
    "\n",
    "        return lowtide \n",
    "\n",
    "    ## Vectorise the hightide calculation\n",
    "    highlows_all = stacked_everything.apply(lambda x: xr.DataArray(highestlowtides(x)))\n",
    "\n",
    "    # ## Unstack and re-format the array\n",
    "    highlows_all = highlows_all.unstack('z')\n",
    "    highlows_all_unstacked = (\n",
    "                        highlows_all\n",
    "                         .reindex(y=highlows_all.y[::-1])\n",
    "                         # .rename({'dim_0':'time'})\n",
    "                         # .rename({'time':'hightide'})\n",
    "                         .to_dataset()#name = 'time')\n",
    "                         [['tide_m','time','y','x']]\n",
    "                        )\n",
    "\n",
    "    ## Calculate exposure using regular method\n",
    "    calculate_quantiles = np.linspace(0, 1, 101)#101)\n",
    "\n",
    "    tide_cq = highlows_all_unstacked.tide_m.quantile(q=calculate_quantiles,dim='time')\n",
    "\n",
    "    # Calculate the tide-height difference between the elevation value and\n",
    "    # each percentile value per pixel\n",
    "    diff = abs(tide_cq - ds.elevation)\n",
    "\n",
    "    # Take the percentile of the smallest tide-height difference as the\n",
    "    # exposure % per pixel\n",
    "    idxmin = diff.idxmin(dim=\"quantile\")\n",
    "\n",
    "    # Convert to percentage\n",
    "    lowtide_exposure = idxmin * 100\n",
    "\n",
    "    # return lowtide_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c6c0d-4af4-4005-a1bf-00a3efb97db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Peak selections in xarray for single pixel\n",
    "# ## Calculations for Spring/Neap/High/Low tides\n",
    "# ## Hardcoded assumption: one spring high tide per 14 day half-lunar cycle\n",
    "\n",
    "# # Extract the modelling freq units\n",
    "# freq_unit = modelled_freq.split()[0][-1]\n",
    "# freq_value = modelled_freq.split()[0][:-1]\n",
    "# # Extract the number of modelled timesteps per 14 days\n",
    "# mod_timesteps = np.timedelta64(14,'D') / np.timedelta64(freq_value,freq_unit)\n",
    "\n",
    "# # Modelledtides for pixel y1x1\n",
    "# test_mt = modelledtides[0].isel(y=1,x=1)\n",
    "\n",
    "# ## Calculate the (spring) highest and lowest tides per 14 day half lunar cycle\n",
    "# springhighs = np.array(argrelmax(modelledtides[0].isel(y=1,x=1).values,\n",
    "#                                 order=(int(mod_timesteps/2)))[0])\n",
    "# springlows = np.array(argrelmin(modelledtides[0].isel(y=1,x=1).values,\n",
    "#                                 order=(int(mod_timesteps/2)))[0])\n",
    "\n",
    "# ## Calculate the neap high and low tides per 14 day half lunar cycle\n",
    "# # Calculate all the high tide maxima\n",
    "# Max_test = np.array(argrelmax(modelledtides[0].isel(y=1,x=1).values)[0])\n",
    "# # Calculate the neap high tide minima per half lunar cycle, based on the number of spring high maxima\n",
    "# neaphighs = np.array(argrelmin(test_mt[Max_test].values,\n",
    "#                               order=(int(ceil((len(test_mt[Max_test])/len(springhighs))/2))))[0])\n",
    "# # Calculate all the low tide minima\n",
    "# Min_test = np.array(argrelmin(modelledtides[0].isel(y=1,x=1).values)[0])\n",
    "# # Calculate the neap low tide maxima per half lunar cycle, based on the number of spring low minima\n",
    "# neaplows = np.array(argrelmax(test_mt[Min_test].values,\n",
    "#                               order=(int(ceil((len(test_mt[Min_test])/len(springlows))/2))))[0])\n",
    "\n",
    "# # if 'Spring_high':\n",
    "# #     time_range = test_mt[springhighs].time.values\n",
    "# # if 'Spring_low':\n",
    "# #     time_range = test_mt[springlows].time.values\n",
    "# # if 'Neap_high':\n",
    "# #     time_range = test_mt[Max_test][neaphighs].time.values\n",
    "# # if 'Neap_low':\n",
    "# #     time_range = test_mt[Min_test][neaplows].time.values\n",
    "\n",
    "# ## Calculate all hightide and lowtide peaks\n",
    "\n",
    "# # Create a dataset to model into, same length as test_mt (modelledtides) but without \n",
    "# # the complication of datetimes\n",
    "# count = np.arange(0,len(test_mt),1)\n",
    "\n",
    "# ## Need to extract the maxima and minima from the high and low tide maxima respectively\n",
    "# Max_max = np.array(argrelmax(test_mt[Max_test].values)[0])\n",
    "# Max_min = np.array(argrelmin(test_mt[Max_test].values)[0])\n",
    "\n",
    "# Min_max = np.array(argrelmax(test_mt[Min_test].values)[0])\n",
    "# Min_min = np.array(argrelmin(test_mt[Min_test].values)[0])\n",
    "\n",
    "\n",
    "# ## Interpolate the high and low spring and neap curves\n",
    "# # neap high tide curve\n",
    "# neap_high_linear = interp1d(Max_test[Max_min], \n",
    "#                             test_mt[Max_test][Max_min].values, \n",
    "#                             bounds_error=False, \n",
    "#                             kind='linear', \n",
    "#                             fill_value='extrapolate'\n",
    "#                            )\n",
    "# neap_high_testline = neap_high_linear(count)\n",
    "# # # spring high tide curve\n",
    "# # spring_high_linear = interp1d(Max_test[Max_max], \n",
    "# #                               test_mt[Max_test][Max_max].values, \n",
    "# #                               bounds_error=False, \n",
    "# #                               kind='linear', \n",
    "# #                               fill_value='extrapolate'\n",
    "# #                              )\n",
    "# # spring_high_testline = spring_high_linear(count)\n",
    "# # neap low tide curve\n",
    "# neap_low_linear = interp1d(Min_test[Min_max], \n",
    "#                            test_mt[Min_test][Min_max].values, \n",
    "#                            bounds_error=False, \n",
    "#                            kind='linear', \n",
    "#                            fill_value='extrapolate')\n",
    "# neap_low_testline = neap_low_linear(count)\n",
    "# # # spring low tide curve\n",
    "# # spring_low_linear = interp1d(Min_test[Min_min], \n",
    "# #                              test_mt[Min_test][Min_min].values, \n",
    "# #                              bounds_error=False, \n",
    "# #                              kind='linear', \n",
    "# #                              fill_value='extrapolate')\n",
    "# # spring_low_testline = spring_low_linear(count)\n",
    "# # turn test_mt (modelledtides) into xr.Dataset\n",
    "# test_mt = test_mt.to_dataset()\n",
    "# # append the extrapolated tidelines for the lowest high tides and\n",
    "# # highest low tides (not really neap - more neap-esque)\n",
    "# test_mt['neap_high_testline'] = (('time'), neap_high_testline)\n",
    "# test_mt['neap_low_testline'] = (('time'), neap_low_testline)\n",
    "# # Extract hightides as all tides higher than/equal to the extrapolated lowest high tide line\n",
    "# hightide = test_mt['tide_m'].where(test_mt['tide_m'] >= test_mt['neap_high_testline'], drop=True)\n",
    "# # Extract lowtides as all tides lower than/equal to the extrapolated highest low tide line\n",
    "# lowtide = test_mt['tide_m'].where(test_mt['tide_m'] <= test_mt['neap_low_testline'], drop=True)\n",
    "# # Extract datetimes to run through exposure module\n",
    "# # if 'Hightide':\n",
    "# #     time_range = hightide.time.values\n",
    "# # if 'Lowtide':\n",
    "# #     time_range = lowtide.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66af89-fb73-4867-9b1b-c61430ce830f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_timerange\n",
    "\n",
    "# dry =  all_timerange.drop(all_timerange\n",
    "#                         [(all_timerange.month == 10) ## Wet season: Oct-Mar\n",
    "#                         |(all_timerange.month == 11)\n",
    "#                         |(all_timerange.month == 12)\n",
    "#                         |(all_timerange.month == 1)\n",
    "#                         |(all_timerange.month == 2)\n",
    "#                         |(all_timerange.month == 3)\n",
    "#                         ])\n",
    "\n",
    "# wet = all_timerange.drop(all_timerange\n",
    "#                         [(all_timerange.month == 4) ## Dry season: Apr-Sep\n",
    "#                         |(all_timerange.month == 5)\n",
    "#                         |(all_timerange.month == 6)\n",
    "#                         |(all_timerange.month == 7)\n",
    "#                         |(all_timerange.month == 8)\n",
    "#                         |(all_timerange.month == 9)\n",
    "#                         ])\n",
    "\n",
    "\n",
    "# dry_modelledtides = pixel_tides(\n",
    "#                     ds,\n",
    "#                     times=dry,\n",
    "#                     model=tide_model,\n",
    "#                     directory = tide_model_dir)\n",
    "\n",
    "# wet_modelledtides = pixel_tides(\n",
    "#                     ds,\n",
    "#                     times=wet,\n",
    "#                     model=tide_model,\n",
    "#                     directory = tide_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510e672-9820-49e0-8235-8ef5cb989b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25956996-ea03-4d2d-8235-bcbcc9d80e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelledtides[0].isel(y=1,x=1).where(modelledtides[0].isel(y=1,x=1).time != "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6058c-407d-4d30-8e9e-8abc57c4a68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dry_modelledtides[0].isel(y=1,x=1).plot(zorder=0)#marker='.', linestyle='')\n",
    "wet_modelledtides[0].isel(y=1,x=1).plot(marker='', linestyle='')\n",
    "\n",
    "# modelledtides.isel(y=1,x=1).where(modelledtides.isel(y=1,x=1) != "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e198ea-3beb-446c-aa13-0754df0d20ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=16\n",
    "\n",
    "test_mt.tide_m[0:-1].plot(zorder=1, label='wet season', color='#1f77b4', figsize=(9, 5),)#, marker='.', linestyle='')\n",
    "\n",
    "dry_modelledtides[0][0:1464].isel(y=1,x=1).plot( label='all tides', color='#ff7f0e')#, marker='.', linestyle='')\n",
    "dry_modelledtides[0][1465:2928].isel(y=1,x=1).plot(color='#ff7f0e')#figsize=(9, 5), label='dry season')#, marker='.', linestyle='')\n",
    "dry_modelledtides[0][2929:].isel(y=1,x=1).plot(color='#ff7f0e')#figsize=(9, 5), label='dry season')#, marker='.', linestyle='')\n",
    "# wet_modelledtides[0].isel(y=1,x=1).plot(marker='', linestyle='')\n",
    "\n",
    "\n",
    "## Plots to check outputs of high and low tide selections\n",
    "# lowtide[0:-1].plot(zorder=2, figsize=(9, 5), label='lowtide')#, marker='.', linestyle='')\n",
    "# lowtide[0:-1].plot(zorder=3, marker='.', linestyle='')\n",
    "\n",
    "# test_mt.neap_high_testline[0:-1].plot()\n",
    "# test_mt.neap_low_testline[0:2000].plot(zorder=10)\n",
    "plt.title('')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(ticks=[])\n",
    "# plt.margins(0)\n",
    "\n",
    "plt.savefig(f\"{output_dir}/{study_area}_{start_date}_{end_date}_px_wetseason\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67038bef-df19-42b3-850c-a7e9efec6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb25c2-a0b3-48b6-9e05-401c88f476e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plots to check outputs of spring and neap tides selections\n",
    "\n",
    "# BEWARE: if this cell isn't working, check test_mt as it was prototyped as an \n",
    "# xr.Dataarray but was later converted to xr.Dataset\n",
    "\n",
    "test_mt.tide_m[1280:1485].plot(zorder=0)#ylim=0) #Modelledtides\n",
    "test_mt.tide_m[Max_test][310:357].plot(marker='o', linestyle='')\n",
    "test_mt.tide_m[Min_test][310:357].plot(marker='o', linestyle='', zorder=1)\n",
    "\n",
    "test_mt.tide_m[springhighs][11:13].plot(marker='o', linestyle='') \n",
    "test_mt.tide_m[springlows][11:13].plot(marker='o', linestyle='', zorder=2) \n",
    "test_mt.tide_m[Max_test][neaphighs][11:13].plot(marker='o', linestyle='')\n",
    "test_mt.tide_m[Min_test][neaplows][11:13].plot(marker='o', linestyle='', zorder=100)\n",
    "\n",
    "plt.plot(test_mt.tide_m[1280:1470].time, neap_high_testline[1280:1470])\n",
    "plt.plot(test_mt.tide_m[1280:1470].time, spring_high_testline[1280:1470])\n",
    "plt.plot(test_mt.tide_m[1280:1470].time, neap_low_testline[1280:1470])\n",
    "plt.plot(test_mt.tide_m[1280:1470].time, spring_low_testline[1280:1470])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981eb9b7-712b-460c-a742-519009a158d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds['lowtide_exposure'] = lowtide_exposure#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46964bd-1dea-4718-b95a-595f5f7339d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['hightide_exposure'] = hightide_exposure#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e6196-8cd1-468d-9fa0-a620ef355e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiderange_day == tiderange_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0eac5-1e67-4a23-a363-dd999fbc2f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save rasters as GeoTIFFs\n",
    "export_intertidal_rasters(ds, prefix=f\"{output_dir}/{study_area}_{start_date}_{end_date}\")\n",
    "# Save rasters as GeoTIFFs\n",
    "# export_intertidal_rasters(hightide_exposure, prefix=f\"{output_dir}/{study_area}_{start_date}_{end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ffaa6-0c2d-4738-aa42-1679d5d07d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983a1a1-05dd-4c69-b556-625ca6c467b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
